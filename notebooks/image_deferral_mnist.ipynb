{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0\n",
      "Using GPU:1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from mnist_train import Net\n",
    "from utils.gpu_utils import restrict_GPU_pytorch\n",
    "from utils.imagenet_utils import accuracy\n",
    "from utils.dataloading_utils import MyIter, MyLoader\n",
    "from new_tta_models import ImageDeferral, ClassWeights, AugWeights, StandardTTA, Original\n",
    "\n",
    "restrict_GPU_pytorch('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mnist_train import Net\n",
    "\n",
    "pcts = [.005, .01, .05, .075,  .1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\n",
    "pct = .005\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('../saved_models/mnist/mnist_cnn_' + str(pct) + '.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../datasets', train=False, download=True, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "hflip_dataset = datasets.MNIST('../datasets', download=True, train=False, transform=transforms.Compose([\n",
    "                           transforms.RandomHorizontalFlip(p=1),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                       ]))\n",
    "vflip_dataset = datasets.MNIST('../datasets', download=True, train=False, transform=transforms.Compose([\n",
    "                           transforms.RandomVerticalFlip(p=1),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                       ]))\n",
    "\n",
    "n_examples = len(dataset)\n",
    "subset_indices = np.arange(n_examples)\n",
    "np.random.shuffle(subset_indices)\n",
    "val_idxs = subset_indices[:int(len(subset_indices)/2)]\n",
    "test_idxs = subset_indices[int(len(subset_indices)/2):]\n",
    "batch_size = 512\n",
    "n_augs = 3\n",
    "orig_val_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(dataset, val_idxs), \n",
    "        batch_size=batch_size, shuffle=False)\n",
    "hflip_val_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(hflip_dataset, val_idxs),\n",
    "                                                batch_size=batch_size, shuffle=False)\n",
    "vflip_val_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(vflip_dataset, val_idxs),\n",
    "                                                batch_size=batch_size, shuffle=False)\n",
    "data_loader = MyLoader([orig_val_loader, hflip_val_loader, vflip_val_loader])\n",
    "\n",
    "\n",
    "orig_test_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(dataset, test_idxs), \n",
    "        batch_size=batch_size, shuffle=False)\n",
    "hflip_test_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(hflip_dataset, test_idxs),\n",
    "                                                batch_size=batch_size, shuffle=False)\n",
    "vflip_test_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(vflip_dataset, test_idxs),\n",
    "                                                batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = MyLoader([orig_test_loader, hflip_test_loader, vflip_val_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_model = ImageDeferral(model,n_augs, 10, 0, 1)\n",
    "def_model.cuda('cuda:0')\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion.cuda('cuda:0')\n",
    "optimizer = torch.optim.SGD(def_model.parameters(), lr=.01, momentum=.9, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "losses = []\n",
    "acc1s = []\n",
    "acc5s = []\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for examples, target in data_loader:\n",
    "        examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "        target = target.cuda('cuda:0', non_blocking=True)\n",
    "        output = def_model(examples)\n",
    "        loss = criterion(output, target)\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        acc1s.append(acc1.item())\n",
    "        acc5s.append(acc5.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.35164184570313 99.34510498046875\n"
     ]
    }
   ],
   "source": [
    "def_model.eval()\n",
    "def_model.cuda('cuda:0')\n",
    "model.cuda('cuda:0')\n",
    "test_acc1s = []\n",
    "test_acc5s = []\n",
    "for examples, target in test_data_loader:\n",
    "    examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "    target = target.cuda('cuda:0', non_blocking=True)    \n",
    "    output = def_model(examples)\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    test_acc1s.append(acc1.item())\n",
    "    test_acc5s.append(acc5.item())\n",
    "print(np.mean(test_acc1s), np.mean(test_acc5s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation learning augmentation weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('../saved_models/mnist/mnist_cnn.pth'))\n",
    "model.eval()\n",
    "aug_model = ClassWeights(model, n_augs, 10)\n",
    "aug_model.cuda('cuda:0')\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion.cuda('cuda:0')\n",
    "optimizer = torch.optim.SGD(aug_model.parameters(), lr=.01, momentum=.9, weight_decay=1e-4)\n",
    "\n",
    "losses = []\n",
    "acc1s = []\n",
    "acc5s = []\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for examples, target in data_loader:\n",
    "        examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "        target = target.cuda('cuda:0', non_blocking=True)\n",
    "        output = aug_model(examples)\n",
    "        loss = criterion(output, target)\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        acc1s.append(acc1.item())\n",
    "        acc5s.append(acc5.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.147161865234374 93.78706970214844\n"
     ]
    }
   ],
   "source": [
    "aug_model.eval()\n",
    "test_acc1s = []\n",
    "test_acc5s = []\n",
    "for examples, target in test_data_loader:\n",
    "    examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "    target = target.cuda('cuda:0', non_blocking=True)    \n",
    "    output = aug_model(examples)\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    test_acc1s.append(acc1.item())\n",
    "    test_acc5s.append(acc5.item())\n",
    "print(np.mean(test_acc1s), np.mean(test_acc5s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3564, 0.6898, 0.3547, 0.4859, 0.4206, 0.3544, 0.3791, 0.2914, 0.3588,\n",
       "         0.3574],\n",
       "        [0.3218, 0.1594, 0.3227, 0.2647, 0.2897, 0.3207, 0.3105, 0.4173, 0.3206,\n",
       "         0.3213],\n",
       "        [0.3218, 0.1508, 0.3227, 0.2494, 0.2897, 0.3248, 0.3105, 0.2914, 0.3206,\n",
       "         0.3213]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_model.sm(aug_model.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97cc186110>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.6876594543457 99.91589584350587\n"
     ]
    }
   ],
   "source": [
    "# See how regular TTA works with this\n",
    "# See how learning just the weights does\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('../saved_models/mnist/mnist_cnn.pth'))\n",
    "model.eval()\n",
    "orig_model = Original(model, 0)\n",
    "orig_model.cuda('cuda:0')\n",
    "orig_model.eval()\n",
    "test_acc1s = []\n",
    "test_acc5s = []\n",
    "all_orig_preds = []\n",
    "for examples, target in test_data_loader:\n",
    "    examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "    target = target.cuda('cuda:0', non_blocking=True)    \n",
    "    output = orig_model(examples)\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    all_orig_preds.extend(np.argmax(output.cpu().numpy(), 1))\n",
    "    test_acc1s.append(acc1.item())\n",
    "    test_acc5s.append(acc5.item())\n",
    "print(np.mean(test_acc1s), np.mean(test_acc5s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluting standard test-time augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.13376922607422 98.77431411743164\n"
     ]
    }
   ],
   "source": [
    "stta_model = StandardTTA(model)\n",
    "stta_model.cuda('cuda:0')\n",
    "test_acc1s = []\n",
    "test_acc5s = []\n",
    "all_targets = []\n",
    "all_stta_preds = []\n",
    "for examples, target in test_data_loader:\n",
    "    examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "    target = target.cuda('cuda:0', non_blocking=True)    \n",
    "    output = stta_model(examples)\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    all_stta_preds.extend(np.argmax(output.cpu().numpy(), 1))\n",
    "    all_targets.extend(target.cpu().numpy())\n",
    "    test_acc1s.append(acc1.item())\n",
    "    test_acc5s.append(acc5.item())\n",
    "print(np.mean(test_acc1s), np.mean(test_acc5s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 569)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stta_preds = np.array(all_stta_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "all_orig_preds = np.array(all_orig_preds)\n",
    "stta_correct = np.where(all_stta_preds == all_targets)[0]\n",
    "stta_incorrect = np.where(all_stta_preds != all_targets)[0]\n",
    "orig_correct = np.where(all_orig_preds == all_targets)[0]\n",
    "orig_incorrect = np.where(all_orig_preds != all_targets)[0]\n",
    "len(set(stta_correct).intersection(orig_incorrect)), len(set(orig_correct).intersection(stta_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4839"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning augmentation specific weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.35157775878906 99.90234375\n",
      "96.34698104858398 100.0\n"
     ]
    }
   ],
   "source": [
    "# Filter to just ones\n",
    "one_idxs = np.where(dataset.targets == 8)[0]\n",
    "one_orig_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(dataset, one_idxs), \n",
    "        batch_size=batch_size, shuffle=False)\n",
    "one_hflip_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(hflip_dataset, one_idxs),\n",
    "                                                batch_size=batch_size, shuffle=False)\n",
    "one_vflip_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(vflip_dataset, one_idxs),\n",
    "                                                batch_size=batch_size, shuffle=False)\n",
    "one_data_loader = MyLoader([one_orig_loader, one_hflip_loader])\n",
    "# Original accuracy\n",
    "# See how regular TTA works with this\n",
    "# See how learning just the weights does\n",
    "orig_model = Original(model, 0)\n",
    "orig_model.cuda('cuda:0')\n",
    "orig_model.eval()\n",
    "test_acc1s = []\n",
    "test_acc5s = []\n",
    "for examples, target in one_data_loader:\n",
    "    examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "    target = target.cuda('cuda:0', non_blocking=True)    \n",
    "    output = orig_model(examples)\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    test_acc1s.append(acc1.item())\n",
    "    test_acc5s.append(acc5.item())\n",
    "print(np.mean(test_acc1s), np.mean(test_acc5s))\n",
    "\n",
    "# See if horizontal flips help\n",
    "stta_model = StandardTTA(model)\n",
    "stta_model.cuda('cuda:0')\n",
    "test_acc1s = []\n",
    "test_acc5s = []\n",
    "for examples, target in one_data_loader:\n",
    "    examples = examples.cuda('cuda:0', non_blocking=True)\n",
    "    target = target.cuda('cuda:0', non_blocking=True)    \n",
    "    output = stta_model(examples)\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    test_acc1s.append(acc1.item())\n",
    "    test_acc5s.append(acc5.item())\n",
    "print(np.mean(test_acc1s), np.mean(test_acc5s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97cc2e7f90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig = next(iter(one_data_loader))\n",
    "ex = orig[0][0][0]\n",
    "plt.imshow(orig[0][1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = orig[0][1].cuda()\n",
    "model(ex)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if learning a class-conditional model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5,   14, ..., 9978, 9984, 9994])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn weights directly from image, and just learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
