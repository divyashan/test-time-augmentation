{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from utils.gpu_utils import restrict_GPU_pytorch\n",
    "restrict_GPU_pytorch(\"0\")\n",
    "\n",
    "# Define new model\n",
    "# Load augmentation outputs for MNIST \n",
    "train_path = '../birds200/five_crop_hflip_scale/model_outputs/val/resnet18_val.h5'\n",
    "test_path = '../birds200/five_crop_hflip_scale/model_outputs/val/resnet18_test.h5'\n",
    "\n",
    "train = h5py.File(train_path, 'r')\n",
    "test = h5py.File(test_path, 'r')\n",
    "dataset = 'birds200'\n",
    "agg_name = 'full_lr'\n",
    "aug_name = 'combo'\n",
    "model_name ='resnet18'\n",
    "n_classes = 200\n",
    "n_augs = 30\n",
    "orig_idx = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TTARegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tta_agg_models import TTARegression\n",
    "agg_models_dir = '../' + dataset + '/five_crop_hflip_scale/agg_models/'\n",
    "model_path = agg_models_dir +model_name+'/'+aug_name + '/full_lr.pth'\n",
    "model = TTARegression(30,n_classes,1, 'even')\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2897, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = train['batch1_inputs'].values\n",
    "val_preds = test['batch1_inouts'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 2897, 200), (30, 2897, 200))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate % of the time expert is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['batch1_inputs', 'batch1_labels']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['batch1_inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process image; output softmax prob; weight outputs based on the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class that does aggregation + deferral prediction\n",
    "class DeferredRegression(nn.Module):\n",
    "    def __init__(self, n_augs, n_classes, orig_idx, temp_scale=1, initialization='even'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.coeffs = nn.Parameter(torch.randn((n_augs, n_classes), requires_grad=True, dtype=torch.float))\n",
    "        self.mix_coeffs = nn.Parameter(torch.randn(2), requires_grad=True, dtype=torch.float)\n",
    "        self.temperature = temp_scale\n",
    "        self.orig_idx = orig_idx\n",
    "        if initialization == 'even':\n",
    "            self.coeffs.data.fill_(1.0/n_augs) \n",
    "        elif initialization== 'original':\n",
    "            self.coeffs.data[0,:].fill_(1)\n",
    "            self.coeffs.data[1,:].fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        x = x/self.temperature\n",
    "        mult = self.coeffs * x\n",
    "        aug_pred = mult.sum(axis=1)\n",
    "        orig_pred = x[self.orig_idx]\n",
    "        final_pred = torch.cat([orig_pred, aug_pred], axis=0)*self.mix_coeffs\n",
    "        final_pred = final_pred.sum(axis=1)\n",
    "        # Function to map augmentation outputs --> deferral value\n",
    "        # Function to map augmentation outputs --> aggregated output\n",
    "        # Normalize to output of [aggregated output, deferral prob]\n",
    "        # Loss function based on this deferral prob and original model predictions\n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train this model on the validation set\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEst on the corresponding test files, see if the deferrals make sense "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
